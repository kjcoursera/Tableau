{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiClas_Classification_Using_SoftMax_MINSTdata.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOweRGj5cyp9pJQWKrNZxoO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjcoursera/Tableau/blob/master/MultiClas_Classification_Using_SoftMax_MINSTdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyGPjBiPIBMD",
        "outputId": "42345ba0-9951-436d-9d5c-1f01caa8fce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVIXV_WdI8Xh"
      },
      "source": [
        "**Load the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivrifISPI0fk",
        "outputId": "53f4239e-34bc-4b07-a119-50a1f9be1802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V11oE-9DJAOV",
        "outputId": "536fecc1-3978-4905-c785-9c8f0bcfae66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train[1917]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  26, 207, 253, 255,  27,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  29, 200, 252, 252, 253,  27,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  26, 200, 252, 252, 220, 133,   6,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          4, 107, 207, 252, 252, 249,  99,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        107, 252, 253, 252, 220,  99,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 120,\n",
              "        253, 253, 255, 253, 133,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 215,\n",
              "        252, 252, 253,  51,   6,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  26, 200, 252,\n",
              "        252, 220, 133,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128, 252, 252,\n",
              "        252, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  79, 253, 252, 252,\n",
              "        236,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 255, 253, 228,\n",
              "         47,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 140, 253, 252, 195,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23, 227, 253, 252,  86,\n",
              "         38, 135,  57,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  29, 252, 253, 252, 109,\n",
              "        224, 252, 253, 177, 137,  10,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  29, 252, 253, 252, 252,\n",
              "        252, 252, 253, 252, 252, 161,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  16, 203, 255, 253, 253,\n",
              "        253, 253, 255, 253, 253, 253, 112,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 140, 253, 252, 252,\n",
              "        252, 127,  27, 228, 252, 252, 112,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 140, 253, 252, 252,\n",
              "        252, 221, 120, 246, 252, 252, 112,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  47, 253, 252, 252,\n",
              "        252, 252, 253, 252, 245, 208,  37,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 174, 252, 252,\n",
              "        252, 252, 253, 252, 118,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAb5vLUyJuFS",
        "outputId": "1e9fc9f6-7bb2-4010-d55d-c0a63be2932a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(x_train[1917])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa844d01588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_pKRAT8J8xe",
        "outputId": "89fdd26d-c610-441e-a5d2-2b01dba30104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Output row #10 of example #2917.\n",
        "x_train[2917][10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2yQlM3VKCM8",
        "outputId": "f1434ff2-7f6b-4f43-e4b2-c1a944162843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Output pixel #16 of row #10 of example #2900.\n",
        "x_train[2917][10][16]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMhC3jEOnkhO"
      },
      "source": [
        "**Normalize the feature values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIBAyJ4KKGmi",
        "outputId": "657fee7b-01da-4f6d-aa4b-eb89a39e3d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "x_train_normalized = x_train/255.0\n",
        "x_test_normalized = x_test/255.0\n",
        "print(x_train_normalized[2900][12]) # Output a normalized row"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.55294118 0.88627451 0.22352941 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu875_eanrIr",
        "outputId": "e0be05bf-91cd-4900-b128-11db71a7cd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
        "  # list_of_metrics should be one of the names shown in:\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the plot_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGDM0Lj0oGy4"
      },
      "source": [
        "def create_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  \n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array. \n",
        "  # Flatten that two-dimensional array into a a one-dimensional \n",
        "  # 784-element array.\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's metrics at each epoch. \n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist   "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrJlbxkOoPP1",
        "outputId": "54056d6a-0cdb-4ce0-8d7f-843a2b0ac226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.003\n",
        "epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1.6469 - accuracy: 0.4756 - val_loss: 0.9029 - val_accuracy: 0.7897\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.8522 - accuracy: 0.7385 - val_loss: 0.5079 - val_accuracy: 0.8695\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6031 - accuracy: 0.8186 - val_loss: 0.3958 - val_accuracy: 0.8979\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5002 - accuracy: 0.8511 - val_loss: 0.3405 - val_accuracy: 0.9070\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4439 - accuracy: 0.8700 - val_loss: 0.3074 - val_accuracy: 0.9154\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.4074 - accuracy: 0.8811 - val_loss: 0.2864 - val_accuracy: 0.9201\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3811 - accuracy: 0.8888 - val_loss: 0.2704 - val_accuracy: 0.9251\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3627 - accuracy: 0.8946 - val_loss: 0.2570 - val_accuracy: 0.9298\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3464 - accuracy: 0.9010 - val_loss: 0.2456 - val_accuracy: 0.9317\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3324 - accuracy: 0.9027 - val_loss: 0.2370 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3181 - accuracy: 0.9083 - val_loss: 0.2278 - val_accuracy: 0.9372\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3093 - accuracy: 0.9101 - val_loss: 0.2209 - val_accuracy: 0.9392\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2980 - accuracy: 0.9136 - val_loss: 0.2133 - val_accuracy: 0.9409\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2884 - accuracy: 0.9167 - val_loss: 0.2088 - val_accuracy: 0.9420\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2864 - accuracy: 0.9161 - val_loss: 0.2040 - val_accuracy: 0.9439\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2762 - accuracy: 0.9179 - val_loss: 0.1985 - val_accuracy: 0.9456\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2685 - accuracy: 0.9223 - val_loss: 0.1932 - val_accuracy: 0.9469\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2612 - accuracy: 0.9232 - val_loss: 0.1892 - val_accuracy: 0.9477\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2568 - accuracy: 0.9249 - val_loss: 0.1863 - val_accuracy: 0.9483\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2482 - accuracy: 0.9262 - val_loss: 0.1835 - val_accuracy: 0.9480\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2463 - accuracy: 0.9275 - val_loss: 0.1795 - val_accuracy: 0.9497\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2372 - accuracy: 0.9294 - val_loss: 0.1765 - val_accuracy: 0.9503\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2353 - accuracy: 0.9295 - val_loss: 0.1732 - val_accuracy: 0.9513\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2307 - accuracy: 0.9315 - val_loss: 0.1699 - val_accuracy: 0.9517\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2276 - accuracy: 0.9324 - val_loss: 0.1676 - val_accuracy: 0.9527\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2280 - accuracy: 0.9323 - val_loss: 0.1659 - val_accuracy: 0.9540\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2222 - accuracy: 0.9338 - val_loss: 0.1638 - val_accuracy: 0.9544\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2168 - accuracy: 0.9347 - val_loss: 0.1631 - val_accuracy: 0.9537\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2122 - accuracy: 0.9365 - val_loss: 0.1598 - val_accuracy: 0.9551\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.2098 - accuracy: 0.9377 - val_loss: 0.1574 - val_accuracy: 0.9562\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2031 - accuracy: 0.9390 - val_loss: 0.1551 - val_accuracy: 0.9553\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2040 - accuracy: 0.9382 - val_loss: 0.1540 - val_accuracy: 0.9567\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2019 - accuracy: 0.9396 - val_loss: 0.1532 - val_accuracy: 0.9574\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1998 - accuracy: 0.9387 - val_loss: 0.1515 - val_accuracy: 0.9569\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1960 - accuracy: 0.9412 - val_loss: 0.1496 - val_accuracy: 0.9582\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1937 - accuracy: 0.9420 - val_loss: 0.1483 - val_accuracy: 0.9588\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1909 - accuracy: 0.9409 - val_loss: 0.1480 - val_accuracy: 0.9588\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1894 - accuracy: 0.9427 - val_loss: 0.1466 - val_accuracy: 0.9590\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1876 - accuracy: 0.9435 - val_loss: 0.1446 - val_accuracy: 0.9603\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1846 - accuracy: 0.9444 - val_loss: 0.1435 - val_accuracy: 0.9597\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1851 - accuracy: 0.9439 - val_loss: 0.1416 - val_accuracy: 0.9615\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1829 - accuracy: 0.9435 - val_loss: 0.1416 - val_accuracy: 0.9593\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1800 - accuracy: 0.9454 - val_loss: 0.1414 - val_accuracy: 0.9603\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1758 - accuracy: 0.9467 - val_loss: 0.1399 - val_accuracy: 0.9614\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1791 - accuracy: 0.9456 - val_loss: 0.1376 - val_accuracy: 0.9617\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1740 - accuracy: 0.9458 - val_loss: 0.1375 - val_accuracy: 0.9618\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1736 - accuracy: 0.9472 - val_loss: 0.1359 - val_accuracy: 0.9623\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1700 - accuracy: 0.9471 - val_loss: 0.1359 - val_accuracy: 0.9632\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1714 - accuracy: 0.9470 - val_loss: 0.1356 - val_accuracy: 0.9621\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1697 - accuracy: 0.9493 - val_loss: 0.1343 - val_accuracy: 0.9629\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1372 - accuracy: 0.9603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13722412288188934, 0.9603000283241272]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeVqqFnSs-7W"
      },
      "source": [
        "**Optimize the model**\n",
        "\n",
        "Experiment with the following:\n",
        "\n",
        "    number of hidden layers\n",
        "    number of nodes in each layer\n",
        "    dropout regularization rate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1EiYqPsrMy",
        "outputId": "1584b5a1-32db-4703-e024-49a83ef382ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  \n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array. \n",
        "  # Flatten that two-dimensional array into a a one-dimensional \n",
        "  # 784-element array.\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "\n",
        "  # Define the second hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.25))\n",
        "\n",
        "  \n",
        "\n",
        "  # Define the second hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's metrics at each epoch. \n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 1.3174 - accuracy: 0.5499 - val_loss: 0.4519 - val_accuracy: 0.8760\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.5449 - accuracy: 0.8306 - val_loss: 0.2772 - val_accuracy: 0.9204\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.3938 - accuracy: 0.8814 - val_loss: 0.2122 - val_accuracy: 0.9388\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.3290 - accuracy: 0.9028 - val_loss: 0.1826 - val_accuracy: 0.9479\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2885 - accuracy: 0.9143 - val_loss: 0.1753 - val_accuracy: 0.9494\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2622 - accuracy: 0.9220 - val_loss: 0.1564 - val_accuracy: 0.9548\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.2395 - accuracy: 0.9280 - val_loss: 0.1415 - val_accuracy: 0.9596\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2259 - accuracy: 0.9318 - val_loss: 0.1369 - val_accuracy: 0.9600\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.2105 - accuracy: 0.9369 - val_loss: 0.1324 - val_accuracy: 0.9617\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.2037 - accuracy: 0.9380 - val_loss: 0.1247 - val_accuracy: 0.9641\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1935 - accuracy: 0.9428 - val_loss: 0.1262 - val_accuracy: 0.9638\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1884 - accuracy: 0.9439 - val_loss: 0.1208 - val_accuracy: 0.9663\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1810 - accuracy: 0.9464 - val_loss: 0.1235 - val_accuracy: 0.9637\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1717 - accuracy: 0.9469 - val_loss: 0.1170 - val_accuracy: 0.9657\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1733 - accuracy: 0.9481 - val_loss: 0.1115 - val_accuracy: 0.9672\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1650 - accuracy: 0.9499 - val_loss: 0.1111 - val_accuracy: 0.9667\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1607 - accuracy: 0.9516 - val_loss: 0.1174 - val_accuracy: 0.9668\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1580 - accuracy: 0.9525 - val_loss: 0.1106 - val_accuracy: 0.9685\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1562 - accuracy: 0.9517 - val_loss: 0.1136 - val_accuracy: 0.9671\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1502 - accuracy: 0.9544 - val_loss: 0.1045 - val_accuracy: 0.9698\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1498 - accuracy: 0.9538 - val_loss: 0.1065 - val_accuracy: 0.9696\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1428 - accuracy: 0.9559 - val_loss: 0.1035 - val_accuracy: 0.9703\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1398 - accuracy: 0.9563 - val_loss: 0.1057 - val_accuracy: 0.9698\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1401 - accuracy: 0.9572 - val_loss: 0.1026 - val_accuracy: 0.9698\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1368 - accuracy: 0.9588 - val_loss: 0.1023 - val_accuracy: 0.9704\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1337 - accuracy: 0.9598 - val_loss: 0.1065 - val_accuracy: 0.9698\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1351 - accuracy: 0.9588 - val_loss: 0.1026 - val_accuracy: 0.9697\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1331 - accuracy: 0.9595 - val_loss: 0.1018 - val_accuracy: 0.9708\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1296 - accuracy: 0.9605 - val_loss: 0.0988 - val_accuracy: 0.9716\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1268 - accuracy: 0.9607 - val_loss: 0.1002 - val_accuracy: 0.9715\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1264 - accuracy: 0.9611 - val_loss: 0.1017 - val_accuracy: 0.9716\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1260 - accuracy: 0.9609 - val_loss: 0.0983 - val_accuracy: 0.9716\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1203 - accuracy: 0.9625 - val_loss: 0.1004 - val_accuracy: 0.9707\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1215 - accuracy: 0.9626 - val_loss: 0.0981 - val_accuracy: 0.9721\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.1261 - accuracy: 0.9616 - val_loss: 0.1022 - val_accuracy: 0.9706\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1235 - accuracy: 0.9616 - val_loss: 0.0968 - val_accuracy: 0.9729\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1178 - accuracy: 0.9633 - val_loss: 0.0955 - val_accuracy: 0.9732\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1188 - accuracy: 0.9638 - val_loss: 0.0992 - val_accuracy: 0.9712\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1114 - accuracy: 0.9649 - val_loss: 0.0999 - val_accuracy: 0.9720\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1152 - accuracy: 0.9648 - val_loss: 0.0956 - val_accuracy: 0.9728\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1165 - accuracy: 0.9642 - val_loss: 0.1006 - val_accuracy: 0.9722\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1177 - accuracy: 0.9641 - val_loss: 0.0939 - val_accuracy: 0.9742\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1123 - accuracy: 0.9639 - val_loss: 0.0981 - val_accuracy: 0.9721\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1083 - accuracy: 0.9656 - val_loss: 0.0973 - val_accuracy: 0.9730\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1127 - accuracy: 0.9649 - val_loss: 0.0985 - val_accuracy: 0.9728\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1146 - accuracy: 0.9649 - val_loss: 0.0962 - val_accuracy: 0.9732\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1117 - accuracy: 0.9651 - val_loss: 0.0947 - val_accuracy: 0.9743\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1102 - accuracy: 0.9657 - val_loss: 0.0948 - val_accuracy: 0.9734\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1098 - accuracy: 0.9655 - val_loss: 0.0981 - val_accuracy: 0.9732\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.1102 - accuracy: 0.9655 - val_loss: 0.0939 - val_accuracy: 0.9737\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1133 - accuracy: 0.9648 - val_loss: 0.0918 - val_accuracy: 0.9741\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1138 - accuracy: 0.9650 - val_loss: 0.0933 - val_accuracy: 0.9748\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1058 - accuracy: 0.9677 - val_loss: 0.0941 - val_accuracy: 0.9748\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1002 - accuracy: 0.9691 - val_loss: 0.0951 - val_accuracy: 0.9748\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.1021 - accuracy: 0.9678 - val_loss: 0.0961 - val_accuracy: 0.9746\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1048 - accuracy: 0.9682 - val_loss: 0.0936 - val_accuracy: 0.9744\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1020 - accuracy: 0.9678 - val_loss: 0.0969 - val_accuracy: 0.9747\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.1018 - accuracy: 0.9689 - val_loss: 0.0907 - val_accuracy: 0.9745\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1025 - accuracy: 0.9681 - val_loss: 0.0923 - val_accuracy: 0.9754\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0995 - accuracy: 0.9700 - val_loss: 0.0928 - val_accuracy: 0.9753\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.1003 - accuracy: 0.9686 - val_loss: 0.0936 - val_accuracy: 0.9747\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0998 - accuracy: 0.9691 - val_loss: 0.0960 - val_accuracy: 0.9733\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.1078 - accuracy: 0.9670 - val_loss: 0.0970 - val_accuracy: 0.9732\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.1010 - accuracy: 0.9696 - val_loss: 0.0983 - val_accuracy: 0.9732\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.1005 - accuracy: 0.9690 - val_loss: 0.0950 - val_accuracy: 0.9733\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0996 - accuracy: 0.9689 - val_loss: 0.0968 - val_accuracy: 0.9747\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.1011 - accuracy: 0.9691 - val_loss: 0.0913 - val_accuracy: 0.9740\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0974 - accuracy: 0.9695 - val_loss: 0.0963 - val_accuracy: 0.9743\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.0976 - accuracy: 0.9696 - val_loss: 0.0954 - val_accuracy: 0.9734\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0965 - accuracy: 0.9695 - val_loss: 0.0916 - val_accuracy: 0.9757\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0931 - accuracy: 0.9707 - val_loss: 0.0927 - val_accuracy: 0.9744\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.0964 - accuracy: 0.9697 - val_loss: 0.0967 - val_accuracy: 0.9748\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0915 - accuracy: 0.9716 - val_loss: 0.0947 - val_accuracy: 0.9742\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0954 - accuracy: 0.9701 - val_loss: 0.0944 - val_accuracy: 0.9747\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.0920 - accuracy: 0.9715 - val_loss: 0.0948 - val_accuracy: 0.9747\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 0.0932 - accuracy: 0.9715 - val_loss: 0.0944 - val_accuracy: 0.9761\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0940 - accuracy: 0.9707 - val_loss: 0.0937 - val_accuracy: 0.9744\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0921 - accuracy: 0.9707 - val_loss: 0.0961 - val_accuracy: 0.9743\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0918 - accuracy: 0.9713 - val_loss: 0.0913 - val_accuracy: 0.9751\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 0.0919 - accuracy: 0.9719 - val_loss: 0.0932 - val_accuracy: 0.9738\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0866 - accuracy: 0.9726 - val_loss: 0.0949 - val_accuracy: 0.9744\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0917 - accuracy: 0.9716 - val_loss: 0.0964 - val_accuracy: 0.9746\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.0943 - accuracy: 0.9711 - val_loss: 0.0950 - val_accuracy: 0.9754\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0896 - accuracy: 0.9721 - val_loss: 0.0955 - val_accuracy: 0.9737\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0920 - accuracy: 0.9713 - val_loss: 0.0923 - val_accuracy: 0.9755\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0904 - accuracy: 0.9723 - val_loss: 0.0950 - val_accuracy: 0.9750\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0923 - accuracy: 0.9712 - val_loss: 0.0957 - val_accuracy: 0.9749\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 0.0919 - accuracy: 0.9721 - val_loss: 0.1001 - val_accuracy: 0.9728\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0930 - accuracy: 0.9719 - val_loss: 0.0948 - val_accuracy: 0.9752\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 0.0928 - accuracy: 0.9710 - val_loss: 0.1001 - val_accuracy: 0.9733\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0930 - accuracy: 0.9712 - val_loss: 0.0986 - val_accuracy: 0.9751\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0915 - accuracy: 0.9708 - val_loss: 0.0957 - val_accuracy: 0.9738\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 1s 79ms/step - loss: 0.0908 - accuracy: 0.9721 - val_loss: 0.0928 - val_accuracy: 0.9746\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 1s 108ms/step - loss: 0.0889 - accuracy: 0.9721 - val_loss: 0.0992 - val_accuracy: 0.9745\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 1s 108ms/step - loss: 0.0874 - accuracy: 0.9726 - val_loss: 0.0931 - val_accuracy: 0.9759\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0856 - accuracy: 0.9736 - val_loss: 0.0956 - val_accuracy: 0.9753\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0858 - accuracy: 0.9736 - val_loss: 0.1008 - val_accuracy: 0.9742\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 1s 110ms/step - loss: 0.0874 - accuracy: 0.9726 - val_loss: 0.0947 - val_accuracy: 0.9751\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 1s 99ms/step - loss: 0.0860 - accuracy: 0.9739 - val_loss: 0.0975 - val_accuracy: 0.9744\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 0.0883 - accuracy: 0.9722 - val_loss: 0.0944 - val_accuracy: 0.9760\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0988 - accuracy: 0.9731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0987689346075058, 0.9731000065803528]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzlzXC8S2spC",
        "outputId": "de28d89d-414f-4b18-fd6c-fc45661721b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  \n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array. \n",
        "  # Flatten that two-dimensional array into a a one-dimensional \n",
        "  # 784-element array.\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "\n",
        "  # Define the second hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  #model.add(tf.keras.layers.Dropout(rate=0.5))\n",
        "\n",
        "   # Define the third hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  #model.add(tf.keras.layers.Dropout(rate=0.1))\n",
        "\n",
        "  # Define the fourth hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's metrics at each epoch. \n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 122ms/step - loss: 1.5021 - accuracy: 0.4677 - val_loss: 0.5651 - val_accuracy: 0.8355\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 1s 108ms/step - loss: 0.5239 - accuracy: 0.8405 - val_loss: 0.2769 - val_accuracy: 0.9190\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.3264 - accuracy: 0.9061 - val_loss: 0.1966 - val_accuracy: 0.9417\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.2427 - accuracy: 0.9291 - val_loss: 0.1561 - val_accuracy: 0.9533\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.2030 - accuracy: 0.9407 - val_loss: 0.1432 - val_accuracy: 0.9572\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.1735 - accuracy: 0.9492 - val_loss: 0.1246 - val_accuracy: 0.9628\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.1565 - accuracy: 0.9531 - val_loss: 0.1111 - val_accuracy: 0.9674\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.1405 - accuracy: 0.9576 - val_loss: 0.1091 - val_accuracy: 0.9664\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.1313 - accuracy: 0.9607 - val_loss: 0.1039 - val_accuracy: 0.9712\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.1216 - accuracy: 0.9625 - val_loss: 0.1021 - val_accuracy: 0.9705\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.1172 - accuracy: 0.9634 - val_loss: 0.0970 - val_accuracy: 0.9725\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.1083 - accuracy: 0.9660 - val_loss: 0.1023 - val_accuracy: 0.9714\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.1019 - accuracy: 0.9677 - val_loss: 0.0903 - val_accuracy: 0.9740\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.1037 - accuracy: 0.9672 - val_loss: 0.0988 - val_accuracy: 0.9713\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0948 - accuracy: 0.9692 - val_loss: 0.0901 - val_accuracy: 0.9756\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0898 - accuracy: 0.9707 - val_loss: 0.0908 - val_accuracy: 0.9729\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0873 - accuracy: 0.9723 - val_loss: 0.0891 - val_accuracy: 0.9744\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0833 - accuracy: 0.9731 - val_loss: 0.0823 - val_accuracy: 0.9769\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0785 - accuracy: 0.9750 - val_loss: 0.0899 - val_accuracy: 0.9762\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0770 - accuracy: 0.9744 - val_loss: 0.0892 - val_accuracy: 0.9756\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0735 - accuracy: 0.9755 - val_loss: 0.0879 - val_accuracy: 0.9749\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0746 - accuracy: 0.9746 - val_loss: 0.0888 - val_accuracy: 0.9762\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0734 - accuracy: 0.9764 - val_loss: 0.0898 - val_accuracy: 0.9741\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0731 - accuracy: 0.9773 - val_loss: 0.0909 - val_accuracy: 0.9761\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 0.0854 - val_accuracy: 0.9763\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0754 - accuracy: 0.9755 - val_loss: 0.0873 - val_accuracy: 0.9766\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0677 - accuracy: 0.9776 - val_loss: 0.0877 - val_accuracy: 0.9769\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0694 - accuracy: 0.9771 - val_loss: 0.0815 - val_accuracy: 0.9781\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0639 - accuracy: 0.9792 - val_loss: 0.0878 - val_accuracy: 0.9769\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0674 - accuracy: 0.9778 - val_loss: 0.0836 - val_accuracy: 0.9779\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.0808 - val_accuracy: 0.9781\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0649 - accuracy: 0.9787 - val_loss: 0.0865 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0622 - accuracy: 0.9791 - val_loss: 0.0846 - val_accuracy: 0.9769\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0596 - accuracy: 0.9805 - val_loss: 0.0835 - val_accuracy: 0.9779\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0598 - accuracy: 0.9803 - val_loss: 0.0855 - val_accuracy: 0.9769\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0562 - accuracy: 0.9818 - val_loss: 0.0813 - val_accuracy: 0.9790\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.0819 - val_accuracy: 0.9798\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 0.0849 - val_accuracy: 0.9788\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0554 - accuracy: 0.9818 - val_loss: 0.0802 - val_accuracy: 0.9797\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0514 - accuracy: 0.9824 - val_loss: 0.0836 - val_accuracy: 0.9791\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0470 - accuracy: 0.9845 - val_loss: 0.0849 - val_accuracy: 0.9781\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0486 - accuracy: 0.9842 - val_loss: 0.0879 - val_accuracy: 0.9786\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0483 - accuracy: 0.9844 - val_loss: 0.0824 - val_accuracy: 0.9790\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0506 - accuracy: 0.9836 - val_loss: 0.0841 - val_accuracy: 0.9780\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0455 - accuracy: 0.9845 - val_loss: 0.0905 - val_accuracy: 0.9775\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0485 - accuracy: 0.9840 - val_loss: 0.0836 - val_accuracy: 0.9784\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0483 - accuracy: 0.9841 - val_loss: 0.0876 - val_accuracy: 0.9788\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0477 - accuracy: 0.9841 - val_loss: 0.0855 - val_accuracy: 0.9787\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0881 - val_accuracy: 0.9774\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0790 - val_accuracy: 0.9803\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0474 - accuracy: 0.9849 - val_loss: 0.0864 - val_accuracy: 0.9796\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0466 - accuracy: 0.9850 - val_loss: 0.0842 - val_accuracy: 0.9793\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0450 - accuracy: 0.9845 - val_loss: 0.0834 - val_accuracy: 0.9798\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.0800 - val_accuracy: 0.9808\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0470 - accuracy: 0.9839 - val_loss: 0.0804 - val_accuracy: 0.9786\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0873 - val_accuracy: 0.9789\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0444 - accuracy: 0.9850 - val_loss: 0.0814 - val_accuracy: 0.9783\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.0855 - val_accuracy: 0.9788\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0447 - accuracy: 0.9859 - val_loss: 0.0868 - val_accuracy: 0.9792\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.0796 - val_accuracy: 0.9802\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 1s 108ms/step - loss: 0.0420 - accuracy: 0.9862 - val_loss: 0.0828 - val_accuracy: 0.9797\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0820 - val_accuracy: 0.9803\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.0794 - val_accuracy: 0.9808\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.0792 - val_accuracy: 0.9807\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0381 - accuracy: 0.9874 - val_loss: 0.0773 - val_accuracy: 0.9810\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 0.0809 - val_accuracy: 0.9812\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.0799 - val_accuracy: 0.9808\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0386 - accuracy: 0.9872 - val_loss: 0.0788 - val_accuracy: 0.9794\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0364 - accuracy: 0.9882 - val_loss: 0.0865 - val_accuracy: 0.9797\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.0849 - val_accuracy: 0.9806\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.0892 - val_accuracy: 0.9802\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.0820 - val_accuracy: 0.9791\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.0812 - val_accuracy: 0.9808\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0357 - accuracy: 0.9879 - val_loss: 0.0862 - val_accuracy: 0.9792\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.0828 - val_accuracy: 0.9796\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0376 - accuracy: 0.9869 - val_loss: 0.0849 - val_accuracy: 0.9797\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0861 - val_accuracy: 0.9803\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.0849 - val_accuracy: 0.9803\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.0901 - val_accuracy: 0.9794\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 0.0833 - val_accuracy: 0.9803\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0386 - accuracy: 0.9873 - val_loss: 0.0792 - val_accuracy: 0.9803\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0362 - accuracy: 0.9877 - val_loss: 0.0872 - val_accuracy: 0.9793\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.0796 - val_accuracy: 0.9804\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.0819 - val_accuracy: 0.9801\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0341 - accuracy: 0.9889 - val_loss: 0.0817 - val_accuracy: 0.9805\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.0857 - val_accuracy: 0.9807\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 1s 106ms/step - loss: 0.0321 - accuracy: 0.9891 - val_loss: 0.0833 - val_accuracy: 0.9812\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0314 - accuracy: 0.9898 - val_loss: 0.0819 - val_accuracy: 0.9809\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.0824 - val_accuracy: 0.9817\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.0885 - val_accuracy: 0.9792\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 1s 107ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.0868 - val_accuracy: 0.9808\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.0858 - val_accuracy: 0.9798\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0304 - accuracy: 0.9899 - val_loss: 0.0869 - val_accuracy: 0.9809\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0857 - val_accuracy: 0.9808\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.0858 - val_accuracy: 0.9801\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0851 - val_accuracy: 0.9801\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0843 - val_accuracy: 0.9805\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0865 - val_accuracy: 0.9795\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0859 - val_accuracy: 0.9803\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0785 - accuracy: 0.9814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.078484445810318, 0.9814000129699707]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArTKjSfNsqhB",
        "outputId": "c1931c74-6865-4f15-e82e-261b02e0c11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "3/16"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}